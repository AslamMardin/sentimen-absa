{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1. Load data dan lexicon\n",
    "# ---------------------------\n",
    "\n",
    "df = pd.read_csv(\"hasil_sentimen_pesantren.csv\")  # file utama kamu\n",
    "positive_words = pd.read_csv(\"positive.csv\", header=None)[0].tolist()\n",
    "negative_words = pd.read_csv(\"negative.csv\", header=None)[0].tolist()\n",
    "\n",
    "stop_words = set(stopwords.words('indonesian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 2. Perbaikan kalimat (dummy)\n",
    "# ---------------------------\n",
    "\n",
    "def simple_refine(text):\n",
    "    # Simulasi perbaikan kalimat: capitalisasi kata pertama, hapus double spasi\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.strip()\n",
    "    text = \" \".join(text.split())\n",
    "    return text.capitalize()\n",
    "\n",
    "df['text_refined'] = df['text_combined'].apply(simple_refine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 3. Preprocessing untuk LDA\n",
    "# ---------------------------\n",
    "\n",
    "def preprocess(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stop_words and w.isalpha()]\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['text_refined'].apply(preprocess)\n",
    "\n",
    "# Buat dictionary dan corpus\n",
    "dictionary = corpora.Dictionary(df['tokens'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['tokens']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49553d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 4. LDA Topic Modeling untuk aspek\n",
    "# ---------------------------\n",
    "\n",
    "num_topics = 10  # sesuai jumlah aspek kamu\n",
    "\n",
    "lda_model = LdaMulticore(corpus, num_topics=num_topics, id2word=dictionary, passes=10, workers=2, random_state=42)\n",
    "\n",
    "# Assign topik utama tiap kalimat\n",
    "def get_main_topic(lda_model, bow):\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    # ambil topik dengan probabilitas tertinggi\n",
    "    if len(topics) == 0:\n",
    "        return -1\n",
    "    return max(topics, key=lambda x: x[1])[0]\n",
    "\n",
    "df['predicted_aspek'] = [get_main_topic(lda_model, bow) for bow in corpus]\n",
    "\n",
    "# Buat mapping aspek (nomor) ke nama aspek (sesuai input user)\n",
    "aspek_map = {\n",
    "    0: 'Kualitas Guru',\n",
    "    1: 'Fasilitas',\n",
    "    2: 'Lingkungan',\n",
    "    3: 'Kegiatan Pondok',\n",
    "    4: 'Pembinaan Karakter',\n",
    "    5: 'Prestasi',\n",
    "    6: 'Akademik',\n",
    "    7: 'Motivasi/Spiritual',\n",
    "    8: 'Sosial',\n",
    "    9: 'Umum'\n",
    "}\n",
    "df['predicted_aspek_label'] = df['predicted_aspek'].map(aspek_map).fillna('Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b202bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 5. Sentimen Lexicon-Based\n",
    "# ---------------------------\n",
    "\n",
    "def lexicon_sentiment(text):\n",
    "    if pd.isna(text):\n",
    "        return \"netral\"\n",
    "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    pos_count = sum(1 for w in words if w in positive_words)\n",
    "    neg_count = sum(1 for w in words if w in negative_words)\n",
    "    if pos_count > neg_count:\n",
    "        return \"positif\"\n",
    "    elif neg_count > pos_count:\n",
    "        return \"negatif\"\n",
    "    else:\n",
    "        return \"netral\"\n",
    "\n",
    "df['predicted_sentimen_lexicon'] = df['text_refined'].apply(lexicon_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f13fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 6. Evaluasi Akurasi & Confusion Matrix\n",
    "# ---------------------------\n",
    "\n",
    "# Asumsi label manual sudah sesuai format\n",
    "# Untuk aspek\n",
    "if 'aspek_manual' in df.columns:\n",
    "    y_true_aspek = df['aspek_manual']\n",
    "    y_pred_aspek = df['predicted_aspek_label']\n",
    "\n",
    "    acc_aspek = accuracy_score(y_true_aspek, y_pred_aspek)\n",
    "    print(f\"Akurasi Aspek: {acc_aspek:.2f}\")\n",
    "\n",
    "    cm_aspek = confusion_matrix(y_true_aspek, y_pred_aspek, labels=list(aspek_map.values()))\n",
    "    disp_aspek = ConfusionMatrixDisplay(confusion_matrix=cm_aspek, display_labels=list(aspek_map.values()))\n",
    "    disp_aspek.plot(cmap='Blues', xticks_rotation=45)\n",
    "    plt.title(\"Confusion Matrix Aspek\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Kolom aspek_manual tidak ditemukan, evaluasi aspek dilewati.\")\n",
    "\n",
    "# Untuk sentimen\n",
    "if 'sentimen_lexicon' in df.columns:\n",
    "    y_true_sentimen = df['sentimen_lexicon'].str.lower()\n",
    "    y_pred_sentimen = df['predicted_sentimen_lexicon']\n",
    "\n",
    "    labels_sentimen = ['positif','netral','negatif']\n",
    "    acc_sentimen = accuracy_score(y_true_sentimen, y_pred_sentimen)\n",
    "    print(f\"Akurasi Sentimen: {acc_sentimen:.2f}\")\n",
    "\n",
    "    cm_sentimen = confusion_matrix(y_true_sentimen, y_pred_sentimen, labels=labels_sentimen)\n",
    "    disp_sentimen = ConfusionMatrixDisplay(confusion_matrix=cm_sentimen, display_labels=labels_sentimen)\n",
    "    disp_sentimen.plot(cmap='Greens')\n",
    "    plt.title(\"Confusion Matrix Sentimen\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Kolom sentimen_lexicon tidak ditemukan, evaluasi sentimen dilewati.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da90ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 7. Visualisasi Aspek dan Sentimen per Ponpes\n",
    "# ---------------------------\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(data=df, x='ponpes', hue='predicted_aspek_label')\n",
    "plt.title(\"Distribusi Aspek per Ponpes\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Aspek', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(data=df, x='ponpes', hue='predicted_sentimen_lexicon')\n",
    "plt.title(\"Distribusi Sentimen per Ponpes\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Sentimen', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Heatmap jumlah kalimat per aspek dan sentimen (gabungan)\n",
    "pivot = df.pivot_table(index='predicted_aspek_label', columns='predicted_sentimen_lexicon', aggfunc='size', fill_value=0)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(pivot, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Jumlah Kalimat per Aspek dan Sentimen\")\n",
    "plt.ylabel(\"Aspek\")\n",
    "plt.xlabel(\"Sentimen\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f983b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 8. Simpan hasil akhir\n",
    "# ---------------------------\n",
    "\n",
    "df.to_csv(\"hasil_analisis_model.csv\", index=False)\n",
    "print(\"Selesai, hasil disimpan ke 'hasil_analisis model.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
